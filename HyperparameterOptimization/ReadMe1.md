
# Hyperparameter Optimization

In this sub-repository, the project of building a Question Answering model was continued. Firstly,
hyperparameter optimization was performed and then the best hyperparameter values were
used to fine-tune the pre-trained model.

## Repository Contents

1. **`HyperparameterOptimization.pdf`**  
   A detailed report describing the work, including the hyperparameter optimization process, fine-tuning process and its importance.

2. **`HyperparameterOptimization.ipynb`**  
   A Jupyter Notebook containing the code for running the Hyperpatameter tuning process.

3. **`RoBERTa Question Answering Model.ipynb`**  
   Code for fine-tuning RoBERTa model with sepcific parameters.

4. **`RoBERTa_QA_ModelTesting.ipynb`**  
   Code for testing fine-tuned RoBERTa model.

5. **`BERT Question Answering Model.ipynb`**  
   Code for fine-tuning BERT model with sepcific parameters.

6. **`Tuned_BERT_QA_ModelTesting.ipynb`**  
   Code for testing fine-tuned BERT model.

7. **`Non_tuned_BERT_QA_ModelTesting.ipynb`**  
   Code for testing non-tuned BERT model.

## Suggested Workflow

For a better understanding, it is recommended to first read the **report** to get an overview of the project and then proceed to explore and run the **code**.
